{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f6f9131-3b44-4e49-bf78-7bab5f13ab48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   GEN_005  GEN_015  GEN_020  GEN_025  GENDVHDI  GENDVMHI  CCC_195  CCC_200  \\\n",
      "0      3.0      3.0      2.0      2.0       2.0       2.0      2.0      2.0   \n",
      "1      3.0      3.0      3.0      6.0       2.0       2.0      1.0      2.0   \n",
      "2      2.0      3.0      3.0      6.0       3.0       2.0      2.0      2.0   \n",
      "3      3.0      3.0      3.0      6.0       2.0       2.0      2.0      2.0   \n",
      "4      5.0      5.0      4.0      6.0       0.0       0.0      2.0      2.0   \n",
      "\n",
      "   GEN_010  GEN_030  ...  ALWDVSTR  DOCAN  CAN_015  CAN_035F  DRGDVYA  \\\n",
      "0      9.0      2.0  ...       6.0    1.0      2.0       6.0      2.0   \n",
      "1      4.0      3.0  ...       6.0    1.0      2.0       6.0      2.0   \n",
      "2      7.0      2.0  ...       6.0    1.0      2.0       6.0      2.0   \n",
      "3      8.0      2.0  ...       6.0    1.0      2.0       6.0      6.0   \n",
      "4      0.0      3.0  ...       6.0    1.0      2.0       6.0      2.0   \n",
      "\n",
      "   DHH_SEX  DHHGAGE  DHHGMS  DHHDGHSZ  EHG2DVH3  \n",
      "0      2.0      3.0     1.0       2.0       3.0  \n",
      "1      1.0      5.0     1.0       2.0       2.0  \n",
      "2      2.0      5.0     2.0       1.0       1.0  \n",
      "3      1.0      5.0     2.0       1.0       1.0  \n",
      "4      1.0      4.0     2.0       1.0       3.0  \n",
      "\n",
      "[5 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "file_path = 'reduced_pumf_mental_health_data.csv'  \n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4897f461-e8c9-4998-bda0-5df603208c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Missing Values  Percentage\n",
      "GEN_005                0         0.0\n",
      "GEN_015                0         0.0\n",
      "GEN_020                0         0.0\n",
      "GEN_025                0         0.0\n",
      "GENDVHDI               0         0.0\n",
      "GENDVMHI               0         0.0\n",
      "CCC_195                0         0.0\n",
      "CCC_200                0         0.0\n",
      "GEN_010                0         0.0\n",
      "GEN_030                0         0.0\n",
      "CIH_025                0         0.0\n",
      "CIH_030A               0         0.0\n",
      "CIH_030F               0         0.0\n",
      "DOALC                  0         0.0\n",
      "ALC_015                0         0.0\n",
      "ALC_020                0         0.0\n",
      "DOALW                  0         0.0\n",
      "ALW_005                0         0.0\n",
      "ALWDVWKY               0         0.0\n",
      "ALWDVDLY               0         0.0\n",
      "ALWDVLTR               0         0.0\n",
      "ALWDVSTR               0         0.0\n",
      "DOCAN                  0         0.0\n",
      "CAN_015                0         0.0\n",
      "CAN_035F               0         0.0\n",
      "DRGDVYA                0         0.0\n",
      "DHH_SEX                0         0.0\n",
      "DHHGAGE                0         0.0\n",
      "DHHGMS                 0         0.0\n",
      "DHHDGHSZ               0         0.0\n",
      "EHG2DVH3               0         0.0\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "missing_percentage = (data.isnull().sum() / len(data)) * 100\n",
    "\n",
    "# Create a DataFrame to summarize the missing values and their percentages\n",
    "missing_summary = pd.DataFrame({'Missing Values': missing_values, 'Percentage': missing_percentage})\n",
    "\n",
    "# Display the summary\n",
    "print(missing_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8fcc575-d74c-473e-856c-ee7cd670b71b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 9281\n",
      "Duplicate rows:\n",
      "        GEN_005  GEN_015  GEN_020  GEN_025  GENDVHDI  GENDVMHI  CCC_195  \\\n",
      "397         2.0      2.0      2.0      6.0       3.0       3.0      2.0   \n",
      "1129        2.0      9.0      1.0      6.0       3.0       9.0      2.0   \n",
      "1181        2.0      2.0      3.0      3.0       3.0       3.0      2.0   \n",
      "1482        1.0      1.0      3.0      6.0       4.0       4.0      2.0   \n",
      "1632        2.0      3.0      1.0      6.0       3.0       2.0      2.0   \n",
      "...         ...      ...      ...      ...       ...       ...      ...   \n",
      "108205      3.0      3.0      3.0      6.0       2.0       2.0      2.0   \n",
      "108224      2.0      2.0      2.0      6.0       3.0       3.0      2.0   \n",
      "108229      1.0      1.0      1.0      6.0       4.0       4.0      2.0   \n",
      "108230      2.0      2.0      2.0      6.0       3.0       3.0      2.0   \n",
      "108234      3.0      3.0      1.0      6.0       2.0       2.0      2.0   \n",
      "\n",
      "        CCC_200  GEN_010  GEN_030  ...  ALWDVSTR  DOCAN  CAN_015  CAN_035F  \\\n",
      "397         2.0      8.0      2.0  ...       6.0    1.0      2.0       6.0   \n",
      "1129        2.0     99.0      9.0  ...       6.0    1.0      9.0       9.0   \n",
      "1181        2.0      8.0      2.0  ...       6.0    1.0      2.0       6.0   \n",
      "1482        2.0     10.0      1.0  ...       6.0    1.0      2.0       6.0   \n",
      "1632        2.0     10.0      1.0  ...       6.0    1.0      2.0       6.0   \n",
      "...         ...      ...      ...  ...       ...    ...      ...       ...   \n",
      "108205      2.0      8.0      2.0  ...       6.0    1.0      2.0       6.0   \n",
      "108224      2.0      9.0      2.0  ...       6.0    1.0      2.0       6.0   \n",
      "108229      2.0     10.0      1.0  ...       2.0    1.0      2.0       6.0   \n",
      "108230      2.0      8.0      2.0  ...       6.0    1.0      2.0       6.0   \n",
      "108234      2.0     10.0      2.0  ...       6.0    1.0      2.0       6.0   \n",
      "\n",
      "        DRGDVYA  DHH_SEX  DHHGAGE  DHHGMS  DHHDGHSZ  EHG2DVH3  \n",
      "397         6.0      2.0      5.0     1.0       2.0       3.0  \n",
      "1129        6.0      1.0      5.0     1.0       2.0       3.0  \n",
      "1181        2.0      1.0      4.0     1.0       2.0       3.0  \n",
      "1482        2.0      1.0      1.0     6.0       2.0       3.0  \n",
      "1632        6.0      2.0      5.0     2.0       1.0       1.0  \n",
      "...         ...      ...      ...     ...       ...       ...  \n",
      "108205      2.0      1.0      5.0     1.0       2.0       3.0  \n",
      "108224      2.0      2.0      1.0     6.0       2.0       3.0  \n",
      "108229      6.0      2.0      5.0     2.0       2.0       3.0  \n",
      "108230      2.0      1.0      1.0     6.0       2.0       3.0  \n",
      "108234      2.0      2.0      1.0     6.0       2.0       3.0  \n",
      "\n",
      "[9281 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = data.duplicated()\n",
    "\n",
    "# Display the number of duplicate rows\n",
    "print(f'Number of duplicate rows: {duplicates.sum()}')\n",
    "\n",
    "# Optionally, display the duplicate rows themselves\n",
    "duplicate_rows = data[duplicates]\n",
    "print('Duplicate rows:')\n",
    "print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b991845-9518-4b87-aa83-b479067d9e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 9281\n",
      "Number of rows before removing duplicates: 108252\n",
      "Number of rows after removing duplicates: 98971\n",
      "Cleaned data saved to path_to_your_cleaned_file.csv\n"
     ]
    }
   ],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = data.duplicated()\n",
    "print(f'Number of duplicate rows: {duplicates.sum()}')\n",
    "\n",
    "# Remove duplicate rows\n",
    "data_cleaned = data.drop_duplicates()\n",
    "\n",
    "# Display the number of rows before and after removing duplicates\n",
    "print(f'Number of rows before removing duplicates: {len(data)}')\n",
    "print(f'Number of rows after removing duplicates: {len(data_cleaned)}')\n",
    "\n",
    "# Optionally, save the cleaned data to a new CSV file\n",
    "cleaned_file_path = 'path_to_your_cleaned_file.csv'  # Replace with your desired file path\n",
    "data_cleaned.to_csv(cleaned_file_path, index=False)\n",
    "\n",
    "print(f'Cleaned data saved to {cleaned_file_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
